# 4. 스파크 SQL과 데이터 프레임: 내장 데이터 소스 소개



이 장에서는 데이터 프레임에 대하여 계속 논의를 이어가며 스파크 SQL과 어떻게 상호작용하는지 살펴본다.



## 4.1. 스파크 애플리케이션에서 스파크 SQL 사용하기



### 4.1.1. 기본 쿼리 예제



## 4.2. SQL 테이블과 뷰



### 4.2.1. 관리형 테이블과 비관리형 테이블



관리형 테이블의 경우 스파크는 메타데이터와 파일 저장소의 데이터를 모두 관리한다.



파일 저장소는 로컬 파일 시스템 또는 HDFS거나 Amazon S3 및 Azure Blob과 같은 객체 저장소일 수도 있다.



비관리형 테이블의 경우 스파크는 오직 메타데이터만 관리하고 카산드라와 같은 외부 데이터 소스에서 데이터를 직접 관리한다.



### 4.2.2. SQL 데이터베이스와 테이블 생성하기



#### 4.2.2.1. 관리형 테이블 생성하기



#### 4.2.2.2. 비관리형 테이블 생성하기



### 4.2.3. 뷰 생성하기



#### 4.2.3.1. 임시 뷰 Vs. 전역 임시 뷰



### 4.2.4. 메타데이터 보기



### 4.2.5. SQL 테이블 캐싱하기



### 4.2.6. 테이블을 데이터 프레임으로 읽기



## 4.3. 데이터 프레임 및 SQL 테이블을 위한 데이터 소스



### 4.3.1. DataFrameReader



### 4.3.2. DataFrameWriter



### 4.3.3. 파케이



#### 4.3.3.1. 파케이 파일을 데이터 프레임으로 읽기



#### 4.3.3.2. 파케이 파일을 Spark SQL 테이블로 읽기



#### 4.3.3.3. 데이터 프레임을 파케이 파일로 쓰기



#### 4.3.3.4. 스파크 SQL 테이블에 데이터 프레임 쓰기



### 4.3.4. JSON



#### 4.3.4.1. JSON 파일을 데이터 프레임으로 읽기



#### 4.3.4.2. 스파크 SQL 테이블로 JSON 파일 읽기



#### 4.3.4.3. 데이터 프레임을 JSON 파일로 쓰기



#### 4.3.4.4. JSON 데이터 소스 옵션



### 4.3.5. CSV



#### 4.3.5.1. CSV 파일을 데이터 프레임으로 읽기



#### 4.3.5.2. CSV 파일을 스파크 SQL 데이블로 읽기



#### 4.3.5.3. 데이터 프레임을 CSV 파일로 쓰기



#### 4.3.5.4. CSV 데이터 소스 옵션



### 4.3.6. 에이브로



#### 4.3.6.1. 에이브로 파일을 데이터 프레임으로 읽기



#### 4.3.6.2. 에이브로 파일을 스파크 SQL 테이블로 읽기



#### 4.3.6.3. 데이터 프레임을 에이브로 파일로 쓰기



#### 4.3.6.4. 에이브로 데이터 소스 옵션



### 4.3.7. orc



#### 4.3.7.1. ORC 파일을 데이터 프레임으로 읽기



#### 4.3.7.2. 스파크 SQL 테이블로 ORC 파일 읽기



#### 4.3.7.3. 데이터 프레임을 ORC 파일로 쓰기



### 4.3.8. 이미지



#### 4.3.8.1. 이미지 파일을 데이터 프레임으로 읽기



### 4.3.9. 이진 파일



#### 4.3.9.1. 데이터 프레임으로 이진 파일 읽기



## 4.4. 요약



이 장에서는 데이터 프레임 API와 스파크 SQL 간의 상호 운용성에 대해 살펴본다.



스파크 SQL의 이점



- 스파크 SQL 및 데이터 프레임 API를 사용하여 관리형 및 비관리형 테이블을 생성할 수 있다.
- 다양한 내장 데이터 소스 및 파일 형식을 읽고 쓸 수 있다.
- 스파크 SQL 테이블 또는 뷰로 저장된 정형화 데이터에 spark.sql 프로그래밍 인터페이스를 사용하여 SQL 쿼리를 실행할 수 있다.
- 스파크 카탈로그를 통해 테이블 및 뷰와 관련된 메타데이터를 검사할 수 있다.
- DataFrameWriter 및 DataFrameReader AIP를 사용할 수 있다.



