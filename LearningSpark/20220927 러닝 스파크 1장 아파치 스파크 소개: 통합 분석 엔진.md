[러닝 스파크](https://www.coupang.com/vp/products/6610958771?itemId=14990203662&vendorItemId=82213171243&src=1042503&spec=10304982&addtag=400&ctag=6610958771&lptag=10304982I14990203662&itime=20220927144347&pageType=PRODUCT&pageValue=6610958771&wPcid=16642574277241977270490&wRef=&wTime=20220927144347&redirect=landing&gclid=CjwKCAjwm8WZBhBUEiwA178UnBy2k7s9pAWcJ2X2hk0uRIpDbVZDlfL_Dfm5tB-OYZDkqJFYQ-JhMhoCyMcQAvD_BwE&campaignid=12207438463&adgroupid=115720946583&isAddedCart=)를 공부해보자.


# 1. 아파치 스파크 소개: 통합 분석 엔진

## 1.1. 스파크의 시작

아파치 스파크의 발전 과정을 살펴보자.

### 1.1.1. 빅데이터와 구글에서의 분산 컴퓨팅

RDBMS 같은 전통적인 저장 시스템을 포함해서 구글이 색인을 만들고 검색할 규모의 인터넷 문서를 다루는 것은 불가능하다.

따라서 구글 파일 시스템(Google File System, GFS), 맵리듀스(MapReduce, MR), 빅테이블(BigTable) 등을 만들었다.

GFS: 클러스터 안에서 상용 서버에 장애 내구성이 있는 분산 파일시스템을 제공

빅테이블: GFS를 기반으로 구조화된 대규모 데이터의 저장 수단을 제공

맵리듀스: 함수형 프로그래밍 기반으로 GFS와 빅테이블 위에서 대규모 데이터 분산 처리가 가능한 새로운 병렬 프로그래밍

### 1.1.2. 야후!에서의 하둡

구글의 GFS 논문에서의 컴퓨팅 차원의 과제와 해결책은 하둡 파일 시스템(Hadoop File System, HDFS)과 분산 컴퓨팅 프레임워크로서의 맵리듀스 구현에 대한 청사진을 제공했다.

2006년 4월에 비영리 재단 [아파치](https://www.apache.org/)로 이관되면서 관련 모듈은 하둡 프레임워크의 일부가 되었다(하둡 공통 모듈, 맵리듀스, HDFS, 아파치 하둡 얀YARN).

HDFS에서 돌아가는 맵리듀스 프레임워크의 단점

1. 번거로운 운영 복잡도로 인해 관리가 쉽지 않다.

2. 일반적인 배치 처리를 위한 맵리듀스 API는 장황하고 많은 양의 기본 셋업 코드를 필요로 하며, 장애 대응은 불안정했다.

3. 방대한 배치 데이터 작업을 수행하면서 많은 MR 태스크가 필요해지면 각 태스크는 이후의 단계들을 위해 중간 과정의 데이터를 로컬 디스크에 써야 했다.

4. 하둡 MR은 일반적인 배치 처리를 위한 대규모 작업에는 적당하지만 머신러닝이나 스트리밍, 상호 반응하는 SQL 계통의 질의 등 다른 워크로드와 연계해 쓰기에는 한계가 있다.

하둡과 MR을 좀 더 간편하고 빠르게 만들 방법은 없었을까?

### 1.1.3. AMP 랩에서의 스파크 초창기

하둡 맵리듀스 작업에 참여해 본 UC 버클리의 연구원들은 스파크(Spark)라고 불리는 프로젝트에서 이 도전(하둡과 MR을 좀 더 간편하고 빠르게 만들 방법은 없었을까?)을 시작했다.

스파크의 초기 논문 데모에서는 특정 작업에 대해서 하둡 맵리듀스보다 10~20배 정도 빨랐다.

더 뛰어난 시스템을 제공하기 위해

1. 더 높은 장애 내구성

2. 병렬성을 극적으로 높이고

3. 반복적이고 상호 작용이 많은 맵리듀스 연산을 위한 중간 결과를 메모리에 저장하고

4. 프로그래밍 모델로 쉽고 구성이 간편한 API를 다양한 언어로 제공하며 다양한 워크로드를 통일성 있게 지원한다.

## 1.2. 아파치 스파크란 무엇인가?

아파치 스파크는 데이터 센터나 클라우드에서 대규모 분산 데이터 처리를 하기 위해 설계된 통합형 엔진이다.

스파크는 중간 연산을 위해 메모리 저장소를 지원하여 하둡 맵리듀스보다 훨씬 빠르게 동작할 수 있다.

스파크는 머신러닝(MLlib), 대화형 질의를 위한 SQL(스파크 SQL), 실시간 데이터 처리를 위한 스트리밍 처리(스파크 스트리밍), 그래프 처리(GraphX) 등을 위해 쉽게 사용 가능한 API들로 이루어진 라이브러리를 갖고 있다.

스파크의 네 개의 핵심 특성은 다음과 같다.

1. 속도

2. 사용 편리성

3. 모듈성

4. 확장성

### 1.2.1. 속도

1. 최근 하드웨어 산업의 눈부신 발전 덕에 가격 및 CPU와 메모리의 성능이 향상했고, 스파크의 내부 구현은 이로부터 많은 이득을 얻었다.

2. 스파크는 질의 연산을 방향성 비순환 그래프(directed acyclic graph, DAG(대그))로 구성한다. 이 DAG의 스케줄러와 질의 최적화 모듈은 효율적인 연산 그래프를 만들어서 각각의 태스크로 분해하여 클러스터의 워커 노드 위에서 병렬 수행될 수 있도록 해 준다.

3. 물리적 실행 엔진인 텅스텐(Tungsten)은 전체적 코드 생성(whole-stage code generation)이라는 기법을 써서 실행을 위한 간결한 코드를 생성해 낸다

4. 모든 중간 결과는 메모리에 유지되며, 디스크 I/O를 제한적으로 사용하므로 성능이 크게 향상된다.

### 1.2.2. 사용 편리성

스파크는 데이터 프레임이나 데이터세트 같은 고수준 데이터 추상화 계층 아래에 유연한 분산 데이터세트(resilient distributed dataset, RDD)라 불리는 핵심적이면서도 단순한 논리 자료구조를 구축하여 단순성을 실현하였다.

연산(operation)의 종류

1. 트랜스포메이션(transformtion)

2. 액션(action)

### 1.2.3. 모듈성

스파크 연산은 다양한 타입의 워크로드에 적용 가능하며, 지원하는 모든 프로그래밍 언어로 표현할 수 있다(스칼라, 자바, 파이썬, SQL, R).

### 1.2.4. 확장성

스파크는 저장보다는 빠른 병렬 연산 엔진에 초점이 맞추어져 있다. 저장과 연산을 모두 포함하는 아파치 하둡과는 달리 스파크는 이 둘을 분리하였다.

## 1.3. 통합된 분석

통합은 스파크에 있어서 설계 철학과 진화를 나타내는 핵심 개념이다.

### 1.3.1. 단일화된 스택으로의 아파치 컴포넌트

#### 1.3.1.1. 스파크 SQL

#### 1.3.1.2. 스파크 MLlib

#### 1.3.1.3. 스파크 정형화 스트리밍

#### 1.3.1.4. GraphX

### 1.3.2. 아파치 스파크의 분산 실행

#### 1.3.2.1. 스파크 드라이버

#### 1.3.2.2. SparkSession

#### 1.3.2.3. 클러스터 매니저

#### 1.3.2.4. 스파크 이그제큐터

#### 1.3.2.5. 배포 모드

#### 1.3.2.6. 분산 데이터와 파티션

## 1.4. 개발자의 경험

### 1.4.1. 스파크는 누가 사용하고 왜 사용하는가

#### 1.4.1.1. 데이터 과학 업무

#### 1.4.1.2. 데이터 엔지니어링 업무

#### 1.4.1.3. 인기 있는 스파크 사용 사례들

### 1.4.2. 커뮤니티의 선택과 확산

